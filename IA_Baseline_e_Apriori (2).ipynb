{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "o2QOjzlCzfHn",
      "metadata": {
        "id": "o2QOjzlCzfHn"
      },
      "source": [
        "# Recomendação de filmes utilizando o dataset do MovieLens\n",
        "## Tratamento dos dados, implementação e comparação entre o método Baseline e o modelo Apriori"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ccDuYXGUzfHu",
      "metadata": {
        "id": "ccDuYXGUzfHu"
      },
      "source": [
        "### Importar Bibliotecas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "pc6oV0EZzfHv",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pc6oV0EZzfHv",
        "outputId": "c89c1efa-8e85-412e-93e7-043b7b86a662"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.23.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: mlxtend in /usr/local/lib/python3.10/dist-packages (0.22.0)\n",
            "Requirement already satisfied: wget in /usr/local/lib/python3.10/dist-packages (3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3.post1)\n",
            "Requirement already satisfied: scipy>=1.2.1 in /usr/local/lib/python3.10/dist-packages (from mlxtend) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from mlxtend) (1.2.2)\n",
            "Requirement already satisfied: matplotlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from mlxtend) (3.7.1)\n",
            "Requirement already satisfied: joblib>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from mlxtend) (1.3.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from mlxtend) (67.7.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->mlxtend) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->mlxtend) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->mlxtend) (4.45.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->mlxtend) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->mlxtend) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->mlxtend) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->mlxtend) (3.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.2->mlxtend) (3.2.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install numpy pandas mlxtend wget"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "QdQIBtvTzfHx",
      "metadata": {
        "id": "QdQIBtvTzfHx"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "g4QaIIdUzfHx",
      "metadata": {
        "id": "g4QaIIdUzfHx"
      },
      "source": [
        "### Dados crus do dataset movieLens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "9Luwnd-QzfHy",
      "metadata": {
        "id": "9Luwnd-QzfHy"
      },
      "outputs": [],
      "source": [
        "import wget\n",
        "# !python3 -m wget https://github.com/mmanzato/MBABigData/raw/master/ml-20m-compact.tar.gz\n",
        "# # Botar referência e créditos ao Marcelo Manzato\n",
        "# !tar -xvzf ml-20m-compact.tar.gz\n",
        "# # Aprox 400 filmes e 11k usuarios"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "NeFuDnV_zfHz",
      "metadata": {
        "id": "NeFuDnV_zfHz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "outputId": "0d3e44da-3171-4c7c-e7fd-27bf9321fba9"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-9de890495218>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Explorar os dados\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmovies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./dataset/movies_sample.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mratings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./dataset/ratings_sample.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mratings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'userId'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'movieId'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rating'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmovies\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'movieId'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'title'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    857\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './dataset/movies_sample.csv'"
          ]
        }
      ],
      "source": [
        "# Explorar os dados\n",
        "movies = pd.read_csv('./dataset/movies_sample.csv')\n",
        "ratings = pd.read_csv('./dataset/ratings_sample.csv')\n",
        "df = ratings[['userId', 'movieId', 'rating']]\n",
        "df = df.merge(movies[['movieId', 'title']])\n",
        "# Mapeamento em idx\n",
        "map_users = {user: idx for idx, user in enumerate(df.userId.unique())}\n",
        "map_items = {item: idx for idx, item in enumerate(df.movieId.unique())}\n",
        "df['userId'] = df['userId'].map(map_users)\n",
        "df['movieId'] = df['movieId'].map(map_items)\n",
        "\n",
        "map_title = {}\n",
        "for _, row in df.iterrows():\n",
        "    map_title[row.movieId] = row.title"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "opsO-eqXzfHz",
      "metadata": {
        "id": "opsO-eqXzfHz"
      },
      "outputs": [],
      "source": [
        "movies.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "xvGhjIX6zfH0",
      "metadata": {
        "id": "xvGhjIX6zfH0"
      },
      "outputs": [],
      "source": [
        "ratings.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "UWRv7GZGzfH1",
      "metadata": {
        "id": "UWRv7GZGzfH1"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "kemK6c7fzfH1",
      "metadata": {
        "id": "kemK6c7fzfH1"
      },
      "source": [
        "### Divisão da base em treino e teste"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "nXitH-H1zfH2",
      "metadata": {
        "id": "nXitH-H1zfH2"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "df_train, df_test = train_test_split(df, test_size=.2, random_state=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "DOzHB3HxzfH2",
      "metadata": {
        "id": "DOzHB3HxzfH2"
      },
      "source": [
        "### Funções para obter informações específicas do DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "npgbVPULzfH2",
      "metadata": {
        "id": "npgbVPULzfH2"
      },
      "outputs": [],
      "source": [
        "# Obter a nota que um usuário deu para um item.\n",
        "def get_rating(df, userId,movieId):\n",
        "    if len(df[(df['userId']==userId)&(df['movieId']==movieId)]) == 0:\n",
        "        return 0\n",
        "    return (df.loc[(df.userId==userId) & (df.movieId == movieId),'rating'].iloc[0])\n",
        "\n",
        "get_rating(df, 6102, 413)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "S3ctqONwzfH2",
      "metadata": {
        "id": "S3ctqONwzfH2"
      },
      "outputs": [],
      "source": [
        "# Obter a lista de todos os filmes que um usuário avaliou.\n",
        "def get_movie_ids(df, userId):\n",
        "    if userId not in df['userId'].values:\n",
        "        return []\n",
        "    return (df.loc[(df.userId==userId),'movieId'].tolist())\n",
        "\n",
        "get_movie_ids(df, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9W_urycjzfH3",
      "metadata": {
        "id": "9W_urycjzfH3"
      },
      "outputs": [],
      "source": [
        "# Obter o título do item dado o seu id.\n",
        "def get_movie_title(movieId):\n",
        "    if movieId not in df['movieId'].values:\n",
        "        return ''\n",
        "    return (df.loc[(df.movieId == movieId),'title'].iloc[0])\n",
        "\n",
        "get_movie_title(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ddnjQ0gzfH3",
      "metadata": {
        "id": "2ddnjQ0gzfH3"
      },
      "outputs": [],
      "source": [
        "# Obter a lista de ratings de um usuário.\n",
        "def get_user_ratings(df, userId):\n",
        "    if userId not in df['userId'].values:\n",
        "        return []\n",
        "    return (df.loc[(df.userId==userId),'rating'].tolist())\n",
        "\n",
        "get_user_ratings(df, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "B3ZkME25zfH4",
      "metadata": {
        "id": "B3ZkME25zfH4"
      },
      "outputs": [],
      "source": [
        "# Obter a média de ratings de um usuário\n",
        "def get_user_mean(df, userId):\n",
        "    return np.mean(get_user_ratings(df, userId))\n",
        "\n",
        "get_user_mean(df, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4j-uRGrnzfH4",
      "metadata": {
        "id": "4j-uRGrnzfH4"
      },
      "outputs": [],
      "source": [
        "# Obter a lista de todos os usuários que avaliaram o filme\n",
        "def get_user_ids(df, movieId):\n",
        "    if movieId not in df['movieId'].values:\n",
        "        return []\n",
        "    return (df.loc[(df.movieId==movieId),'userId'].tolist())\n",
        "\n",
        "get_user_ids(df, 10)[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "E9IZ9qx9zfH4",
      "metadata": {
        "id": "E9IZ9qx9zfH4"
      },
      "outputs": [],
      "source": [
        "# Obter todas as notas do filme\n",
        "def get_movie_ratings(df, movieId):\n",
        "    if movieId not in df['movieId'].values:\n",
        "        return []\n",
        "    return (df.loc[(df.movieId==movieId),'rating'].tolist())\n",
        "\n",
        "get_movie_ratings(df, 0)[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "iAnl9_8ozfH4",
      "metadata": {
        "id": "iAnl9_8ozfH4"
      },
      "outputs": [],
      "source": [
        "# Obter a média de notas do filme\n",
        "def get_movie_mean(df, movieId):\n",
        "    return np.mean(get_movie_ratings(df, movieId))\n",
        "\n",
        "get_movie_mean(df, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6am8sMy9DUur"
      },
      "outputs": [],
      "source": [
        "# Obter a lista de ratings de um usuário.\n",
        "def get_user_movie_rate(df, userId, minRate = 0):\n",
        "    if userId not in df['userId'].values:\n",
        "        return []\n",
        "\n",
        "    if minRate:\n",
        "        return (df.loc[(df.userId==userId) & \\\n",
        "                (df.rating >= minRate),['movieId', 'rating']])\n",
        "\n",
        "    return (df.loc[(df.userId==userId),['movieId', 'rating']])\n",
        "\n",
        "get_user_movie_rate(df, 0, 5)"
      ],
      "id": "6am8sMy9DUur"
    },
    {
      "cell_type": "markdown",
      "id": "EbHZiyOkzfH4",
      "metadata": {
        "id": "EbHZiyOkzfH4"
      },
      "source": [
        "# Método Baseline\n",
        "### Método simples para predição de avaliações baseado em tendências de cada usuário e item\n",
        "\n",
        "> Recomeda filmes considerando o contexto e os dados tanto dos filmes quanto dos usuários, e a associação entre os filmes e os usuários"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0wF0fZuyzfH5",
      "metadata": {
        "id": "0wF0fZuyzfH5"
      },
      "outputs": [],
      "source": [
        "# Calcula a média global, o viés referente ao filme e ao usuário\n",
        "def get_bias(df):\n",
        "    c = 1\n",
        "    global_mean = df['rating'].mean()\n",
        "    movie_list = df['movieId'].unique()\n",
        "    movie_bias = {}\n",
        "    for i in movie_list:\n",
        "        users = get_user_ids(df, i)\n",
        "        movie_bias[i] = sum((get_rating(df, u, i)-global_mean) for u in users) / (len(users) + c)\n",
        "\n",
        "    user_list = df['userId'].unique()\n",
        "    user_bias = {}\n",
        "    for u in user_list:\n",
        "        items = get_movie_ids(df, u)\n",
        "        user_bias[u] = sum((get_rating(df, u, i)-global_mean-movie_bias[i]) for i in items) / (len(items) + c)\n",
        "\n",
        "    return global_mean, user_bias, movie_bias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "YfTwO_QszfH5",
      "metadata": {
        "id": "YfTwO_QszfH5"
      },
      "outputs": [],
      "source": [
        "# Recomenda filmes que o usuário ainda não assistiu\n",
        "def RecommendMovies(df, userId, globalMean, userBias, movieBias, k = 5):\n",
        "    movie_list = df['movieId'].unique()\n",
        "    watched = get_movie_ids(df, userId)\n",
        "    recommend = []\n",
        "    for i in movie_list:\n",
        "        if(not i in watched):\n",
        "             # Calcula a suposta nota para o filme\n",
        "            recommendation_score = globalMean + userBias[userId] + movieBias[i]\n",
        "\n",
        "            recommend.append((i, recommendation_score))\n",
        "\n",
        "      # Ordena de forma crescente a lista de filmes recomendados pela nota\n",
        "    recommend.sort(key=lambda x: x[1], reverse=True)\n",
        "    return recommend[:k]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "nlr6kHo5zfH5",
      "metadata": {
        "id": "nlr6kHo5zfH5"
      },
      "outputs": [],
      "source": [
        "train_global_mean, train_user_bias, train_movie_bias = get_bias(df_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u2yVHffDDUur"
      },
      "outputs": [],
      "source": [
        "print(train_user_bias)\n",
        "print(train_movie_bias)"
      ],
      "id": "u2yVHffDDUur"
    },
    {
      "cell_type": "markdown",
      "id": "ozhC4A1XzfH6",
      "metadata": {
        "id": "ozhC4A1XzfH6"
      },
      "source": [
        "### TODO: Avaliação do desempenho do algoritmo baseline\n",
        "\n",
        "### Método que para cada usuário pega no conjunto de teste os filmes que o usuário avaliou bem (rating > 3 por exemplo) e verifica se este filme foi de fato recomendado pelo método Baseline na função RecommendMovies\n",
        "### Usar plots?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2zGpQDoGDUus"
      },
      "outputs": [],
      "source": [
        "# Verifica se a recomendação sugerida pelo método Baseline é um filme\n",
        "# que o usuário realmente assistiu e deu uma nota maior ou igual a minRate.\n",
        "def check_recomendations(dfTrain, dfTest, globalMean, userBias,\n",
        "                         movieBias, users, minRate, k):\n",
        "\n",
        "    # Array com a quantidade de vídeos assistidos & recomendados\n",
        "    # corretamente pelo baseline para cada usuário\n",
        "    found = [0]*len(users)\n",
        "\n",
        "    for idx, user in enumerate(users):\n",
        "        recomendation = RecommendMovies(dfTrain, user, globalMean,\n",
        "                                        userBias, movieBias, k=k)\n",
        "\n",
        "        test_movies = get_user_movie_rate(dfTest, user, minRate=minRate)\n",
        "\n",
        "        test_movies_list = []\n",
        "        if len(test_movies) != 0:\n",
        "            test_movies_list = test_movies['movieId'].tolist()\n",
        "\n",
        "            for movie in recomendation:\n",
        "                # Verifica se o filme (idMovie) recomendado está na lista de filmes assistidos\n",
        "                if movie[0] in test_movies_list:\n",
        "                    found[idx] += 1\n",
        "\n",
        "    return found"
      ],
      "id": "2zGpQDoGDUus"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gVDH5gnTDUus"
      },
      "outputs": [],
      "source": [
        "users = df_test['userId'].unique().tolist()\n",
        "min_rate = 3\n",
        "found_5 = check_recomendations(df_train, df_test, train_global_mean, train_user_bias,\n",
        "                             train_movie_bias, users, min_rate, 5)\n",
        "found_10 = check_recomendations(df_train, df_test, train_global_mean, train_user_bias,\n",
        "                             train_movie_bias, users, min_rate, 10)\n",
        "found_20 = check_recomendations(df_train, df_test, train_global_mean, train_user_bias,\n",
        "                             train_movie_bias, users, min_rate, 20)\n",
        "found_30 = check_recomendations(df_train, df_test, train_global_mean, train_user_bias,\n",
        "                             train_movie_bias, users, min_rate, 30)\n",
        "found_40 = check_recomendations(df_train, df_test, train_global_mean, train_user_bias,\n",
        "                             train_movie_bias, users, min_rate, 40)\n",
        "\n",
        "print('Média de recomendações vistas para', 5,'recomendações do baseline:', np.mean(found_5))\n",
        "print('Média de recomendações vistas para', 10,'recomendações do baseline:', np.mean(found_10))\n",
        "print('Média de recomendações vistas para', 20,'recomendações do baseline:', np.mean(found_20))\n",
        "print('Média de recomendações vistas para', 30,'recomendações do baseline:', np.mean(found_30))\n",
        "print('Média de recomendações vistas para', 40,'recomendações do baseline:', np.mean(found_40))"
      ],
      "id": "gVDH5gnTDUus"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7PXam_-aDUus"
      },
      "outputs": [],
      "source": [
        "# Erro médio absoluto entre as notas previstas e as notas de avaliações reais\n",
        "amt_movies = df_test['movieId'].unique().size\n",
        "\n",
        "users = df_test['userId'].unique().tolist()\n",
        "users.sort()\n",
        "amt_users = len(users)\n",
        "\n",
        "# Array que armazenará a diferença absoluta média para cada usuário\n",
        "diff = []\n",
        "for user in users:\n",
        "    # Nota de recomendação para todos os filmes dado o usuário i\n",
        "    recomendation = RecommendMovies(df_train, user, train_global_mean,\n",
        "                                        train_user_bias, train_movie_bias, k=amt_movies)\n",
        "    watched_movies = get_user_movie_rate(df_test, user)\n",
        "\n",
        "    mean = []\n",
        "    if len(watched_movies) > 0:\n",
        "        idmovies = watched_movies['movieId'].tolist()\n",
        "        ratemovies = watched_movies['rating'].tolist()\n",
        "\n",
        "        dictMovieRate = {idMovie:rateMovie for idMovie, rateMovie in zip(idmovies, ratemovies)}\n",
        "\n",
        "        for idx, movie in enumerate(recomendation):\n",
        "            # Se o usuário já assistiu o filme, calcula-se a diferença absoluta e adiciona-se ao array\n",
        "            if dictMovieRate.get(movie[0], None):\n",
        "                mean.append(abs(dictMovieRate[movie[0]] - movie[1]))\n",
        "\n",
        "        if mean:\n",
        "            diff.append((user, np.mean(mean)))\n",
        "            mean = []\n",
        "\n",
        "print(diff)"
      ],
      "id": "7PXam_-aDUus"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kVYyuZrODUut"
      },
      "outputs": [],
      "source": [
        "# Geração de vetor apenas com os erros para plot\n",
        "diff_errors = [erro[1] for erro in diff]\n",
        "\n",
        "# Média global dos erros\n",
        "mean_error = np.mean(diff_errors)"
      ],
      "id": "kVYyuZrODUut"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-C-gK4idDUut"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15, 6))\n",
        "plt.bar(range(len(diff_errors)), diff_errors, color=np.where(diff_errors < mean_error, 'red', 'blue'))\n",
        "\n",
        "plt.axhline(y=np.mean(diff_errors), color='r', linestyle='--', label='Média')\n",
        "\n",
        "plt.xlabel('Usuário')\n",
        "plt.ylabel('Erro médio')\n",
        "\n",
        "upper = np.sum(diff_errors >= mean_error)\n",
        "bottom = len(diff_errors) - upper\n",
        "legend = f'Valores acima da média: {upper}\\\n",
        "            \\nValores abaixo da média: {bottom}'\n",
        "plt.legend(title=legend)\n",
        "\n",
        "plt.title('Erro médio das avaliações para cada usuário')\n",
        "plt.show()"
      ],
      "id": "-C-gK4idDUut"
    },
    {
      "cell_type": "markdown",
      "id": "NW_Q0fUUzfH6",
      "metadata": {
        "id": "NW_Q0fUUzfH6"
      },
      "source": [
        "# Modelo Apriori\n",
        "\n",
        "> Recomenda filmes considerando principalmente o contexto dos filmes e a relação (associação) entre eles"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "J2Hyxy4v09Nb",
      "metadata": {
        "id": "J2Hyxy4v09Nb"
      },
      "source": [
        "### Pré-processamento e criação da tabela de filmes assistidos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1BX-ovijzfH6",
      "metadata": {
        "id": "1BX-ovijzfH6"
      },
      "outputs": [],
      "source": [
        "df_pivot = df.pivot(index='userId', columns='title', values='rating').fillna(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "JFJPdX_g0gCi",
      "metadata": {
        "id": "JFJPdX_g0gCi"
      },
      "outputs": [],
      "source": [
        "df_pivot = df_pivot.astype('int64')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "OOZBUNs_0g2R",
      "metadata": {
        "id": "OOZBUNs_0g2R"
      },
      "outputs": [],
      "source": [
        "df_pivot = df_pivot.applymap(lambda x: 1 if x > 0 else 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "BrCEOdoT0wGU",
      "metadata": {
        "id": "BrCEOdoT0wGU"
      },
      "outputs": [],
      "source": [
        "df_pivot.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70fTmWfV1Npr",
      "metadata": {
        "id": "70fTmWfV1Npr"
      },
      "source": [
        "### Treinando o modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "NIe3MPN41Tju",
      "metadata": {
        "id": "NIe3MPN41Tju"
      },
      "outputs": [],
      "source": [
        "from mlxtend.frequent_patterns import apriori\n",
        "\n",
        "frequent_itemset = apriori(df_pivot, min_support=0.07, use_colnames=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Hkx4yHOq1YNi",
      "metadata": {
        "id": "Hkx4yHOq1YNi"
      },
      "outputs": [],
      "source": [
        "frequent_itemset.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Q4klz5ve1ceT",
      "metadata": {
        "id": "Q4klz5ve1ceT"
      },
      "outputs": [],
      "source": [
        "from mlxtend.frequent_patterns import association_rules\n",
        "\n",
        "rules = association_rules(frequent_itemset, metric=\"lift\", min_threshold=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-nJwbXsP1hgi",
      "metadata": {
        "id": "-nJwbXsP1hgi"
      },
      "outputs": [],
      "source": [
        "rules.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "CI-KhU501uZy",
      "metadata": {
        "id": "CI-KhU501uZy"
      },
      "source": [
        "### Resultados\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5-Y30iA01wOL",
      "metadata": {
        "id": "5-Y30iA01wOL"
      },
      "outputs": [],
      "source": [
        "df_res = rules.sort_values(by=['lift'], ascending=False)\n",
        "df_res.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "k2g2N38q2Os8",
      "metadata": {
        "id": "k2g2N38q2Os8"
      },
      "source": [
        "### Testando o modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lM5688ft2TW6",
      "metadata": {
        "id": "lM5688ft2TW6"
      },
      "outputs": [],
      "source": [
        "#movie_test = 'I, Robot (2004)\n",
        "movie_list_test = get_movie_ids(df, 1) # Pega a lista de ids de filmes que o usuário 1 avaliou\n",
        "\n",
        "# Pega os respectivos títulos\n",
        "for i in range(len(movie_list_test)):\n",
        "\tmovie_list_test[i] = get_movie_title(movie_list_test[i])\n",
        "\n",
        "movie_list_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "PZCcbqcM124z",
      "metadata": {
        "id": "PZCcbqcM124z"
      },
      "outputs": [],
      "source": [
        "# Com base nos filmes avaliados, pega as recomendações de cada um e armazena\n",
        "movies = []\n",
        "for movie in movie_list_test:\n",
        "    df_test = df_res[df_res['antecedents'].apply(lambda x: len(x) == 1 and next(iter(x)) == movie)]\n",
        "    df_test = df_test[df_test['lift'] > 1.5]\n",
        "    movies.extend(df_test['consequents'].values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "RQ3I8xRr2NIB",
      "metadata": {
        "id": "RQ3I8xRr2NIB"
      },
      "outputs": [],
      "source": [
        "movie_list = []\n",
        "for movie in movies:\n",
        "    for title in movie:\n",
        "        movie_list.append(title)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4cDses5e3PDy",
      "metadata": {
        "id": "4cDses5e3PDy"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "\n",
        "# Ordena o vetor pelos mais mais repetidos primeiro\n",
        "def sort_by_frequency(array):\n",
        "    # Contar a frequência de cada elemento no array\n",
        "    count = Counter(array)\n",
        "\n",
        "    # Ordenar o array com base na contagem de repetições de cada elemento\n",
        "    sorted_array = sorted(array, key=lambda x: count[x], reverse=True)\n",
        "\n",
        "    return sorted_array\n",
        "\n",
        "# Remove os repetidos depois da ordenação\n",
        "def remove_repeated(array):\n",
        "    new_array = []\n",
        "    seen_items = set()\n",
        "\n",
        "    for movie in array:\n",
        "        if movie not in seen_items:\n",
        "            new_array.append(movie)\n",
        "            seen_items.add(movie)\n",
        "\n",
        "    return new_array\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nvz4X2dIDUu1"
      },
      "outputs": [],
      "source": [
        "movie_list = remove_repeated(sort_by_frequency(movie_list))\n",
        "movie_list[:10]"
      ],
      "id": "nvz4X2dIDUu1"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Avaliação do modelo Apriori"
      ],
      "metadata": {
        "id": "oOTfjR9gDpnU"
      },
      "id": "oOTfjR9gDpnU"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este teste gera todas regras geradas, para averiguar a preditibilidade das regras que o algoritmo gera."
      ],
      "metadata": {
        "id": "STaOotwHFGuE"
      },
      "id": "STaOotwHFGuE"
    },
    {
      "cell_type": "code",
      "source": [
        "allRules = association_rules(frequent_itemset, metric=\"lift\")\n",
        "evaluate = allRules.sort_values(by=['lift'], ascending=True)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(range(len(evaluate)), evaluate['lift'], align='center', color='skyblue')\n",
        "plt.axhline(y=1, color='red', linestyle='--', linewidth=2, label='Limiar de Lift Preditivo')\n",
        "plt.xlabel('Regras de Associação')\n",
        "plt.ylabel('Valor de Lift')\n",
        "plt.title('Lift das Regras de Associação')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Wtn63_oaD910"
      },
      "id": "Wtn63_oaD910",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RkeYh8faDUu2"
      },
      "source": [
        "# TODO\n",
        "# Modelo K-Nearest-Neighbors\n",
        "\n",
        "> Recomenda filmes com base nas preferências de usuários semelhantes"
      ],
      "id": "RkeYh8faDUu2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "66odOG_eDUu2"
      },
      "outputs": [],
      "source": [
        "!pip install scikit-surprise\n",
        "\n",
        "from surprise import Dataset, Reader, KNNBasic\n",
        "\n",
        "reader = Reader(rating_scale=(1, 5))\n",
        "data = Dataset.load_from_df(df[['userId', 'movieId', 'rating']], reader)"
      ],
      "id": "66odOG_eDUu2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ce5io6UDUu2"
      },
      "outputs": [],
      "source": [
        "# Essa função Percorre todos os dados de treinamento disponíveis e extrai informações necessárias para construir o conjunto\n",
        "# de treinamento. Isso inclui o conjunto completo de usuários, itens e avaliações.\n",
        "trainset = data.build_full_trainset()\n",
        "\n",
        "# Aqui estabelecemos as opções de similaridade do KNN usando cosseno (por conta de sua invariância a escala) e explicitando\n",
        "# que as recomendações são baseadas nos usuários\n",
        "sim_options = {'name': 'cosine', 'user_based': True}\n",
        "#model = KNNBasic(sim_options=sim_options)\n",
        "#model.fit(trainset)"
      ],
      "id": "3ce5io6UDUu2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CQamviLtDUu2"
      },
      "outputs": [],
      "source": [
        "user_id_to_predict = 1  # Aqui é estabelecido o usuário em questão\n",
        "items_to_ignore = df[df['userId'] == user_id_to_predict]['movieId'].tolist() # Aqui guardamos os filmes já avaliados pelo usuário\n",
        "\n",
        "# Obtém IDs de filmes ainda não avaliados pelo usuário\n",
        "all_movie_ids = df['movieId'].unique()\n",
        "movies_to_predict = [movie_id for movie_id in all_movie_ids if movie_id not in items_to_ignore]\n",
        "\n",
        "# Gera previsões para os filmes não avaliados\n",
        "predictions = [model.predict(user_id_to_predict, movie_id) for movie_id in movies_to_predict]\n",
        "\n",
        "# Organiza as previsões em ordem decrescente de estimativa de classificação\n",
        "predictions.sort(key=lambda x: x.est, reverse=True)\n",
        "\n",
        "# Obtém os IDs dos filmes recomendados\n",
        "recommended_movie_ids = [prediction.iid for prediction in predictions]\n",
        "\n",
        "# Mapeia os IDs dos filmes recomendados para os títulos reais.\n",
        "recommended_movies = df[df['movieId'].isin(recommended_movie_ids)][['movieId', 'title']].drop_duplicates()\n",
        "\n",
        "recommended_movies[:10]"
      ],
      "id": "CQamviLtDUu2"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}